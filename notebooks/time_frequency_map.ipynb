{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mne\n",
    "sys.path.append('D:/capachinos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eeg_analysis.preprocessing.eeg_file import EEGFile\n",
    "from src.eeg_analysis.preprocessing.eeg_preprocessor import EEGPreprocessor\n",
    "from src.eeg_analysis.analysis.power_spectral import PowerSpectralAnalysis\n",
    "\n",
    "participant_id = 1\n",
    "vhdr_path = r'D:\\Anesthesia_Research_Fellow\\CA-01\\CA-01.vhdr'\n",
    "vmrk_path = r'D:\\Anesthesia_Research_Fellow\\CA-01\\CA-01.vmrk'\n",
    "eeg_path = r'D:\\Anesthesia_Research_Fellow\\CA-01\\CA-01.eeg'\n",
    "\n",
    "eeg_file = EEGFile(participant_id, vhdr_path, vmrk_path, eeg_path)\n",
    "eeg_file.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "EEGPreprocessor.get_segments() missing 1 required positional argument: 'length'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m\n\u001b[0;32m      9\u001b[0m epoch_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[0;32m     11\u001b[0m sequence_of_operations \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     12\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdownsample\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_fs\u001b[39m\u001b[38;5;124m'\u001b[39m: target_fs}),\n\u001b[0;32m     13\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevents_df\u001b[39m\u001b[38;5;124m'\u001b[39m: eeg_file\u001b[38;5;241m.\u001b[39mevents_df}),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconcatenate_data_excluding_noisy_segments\u001b[39m\u001b[38;5;124m'\u001b[39m, {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpadding\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     21\u001b[0m ]\n\u001b[1;32m---> 22\u001b[0m \u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_of_operations\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\capachinos\\src\\eeg_analysis\\preprocessing\\eeg_preprocessor.py:406\u001b[0m, in \u001b[0;36mEEGPreprocessor.process\u001b[1;34m(self, operations)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_name \u001b[38;5;129;01min\u001b[39;00m operations_map:\n\u001b[0;32m    405\u001b[0m     operation_method \u001b[38;5;241m=\u001b[39m operations_map[op_name]\n\u001b[1;32m--> 406\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43moperation_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meeg_data \u001b[38;5;241m=\u001b[39m result\n",
      "\u001b[1;31mTypeError\u001b[0m: EEGPreprocessor.get_segments() missing 1 required positional argument: 'length'"
     ]
    }
   ],
   "source": [
    "preprocessor = EEGPreprocessor(eeg_file)\n",
    "\n",
    "target_fs = 250\n",
    "window_size = 10\n",
    "step_size = 5\n",
    "order = 5\n",
    "low_cutoff = 0.5\n",
    "high_cutoff = 55\n",
    "epoch_length = 30\n",
    "\n",
    "sequence_of_operations = [\n",
    "    ('downsample', {'target_fs': target_fs}),\n",
    "    ('create_epochs', {'events_df': eeg_file.events_df}),\n",
    "    # ('detrend', {'window_size': window_size, 'step_size': step_size}),\n",
    "    # ('re_reference', {'reference_type': 'average'}),\n",
    "    ('bandpass_filter', {'order': order,'low_cutoff': low_cutoff, 'high_cutoff': high_cutoff}),\n",
    "    ('calculate_z_score', {}),\n",
    "    ('get_segments', {'length':2}),\n",
    "    ('mark_exclude_segments', {'min_channels':4}),\n",
    "    ('concatenate_data_excluding_noisy_segments', {'padding':'zeros'})\n",
    "]\n",
    "preprocessor.process(sequence_of_operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.calculate_z_score()\n",
    "preprocessor.get_segments(2)\n",
    "preprocessor.mark_exclude_segments(min_channels=4)\n",
    "preprocessor.concatenate_data_excluding_noisy_segments(padding = 'zeros')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_spectral = PowerSpectralAnalysis(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpower_spectral\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_power_spectral\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\capachinos\\src\\eeg_analysis\\analysis\\power_spectral.py:35\u001b[0m, in \u001b[0;36mPowerSpectralAnalysis.calculate_power_spectral\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Create an MNE Info object with the properties of your data\u001b[39;00m\n\u001b[0;32m     34\u001b[0m ch_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchannel_names  \u001b[38;5;66;03m# Update with real channel names\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m ch_types \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meeg\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16\u001b[39m \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmisc\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m (\u001b[43mdata_to_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m     36\u001b[0m sfreq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_frequency\n\u001b[0;32m     37\u001b[0m info \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mcreate_info(ch_names\u001b[38;5;241m=\u001b[39mch_names, sfreq\u001b[38;5;241m=\u001b[39msfreq, ch_types\u001b[38;5;241m=\u001b[39mch_types)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "power_spectral.calculate_power_spectral()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capachinos_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
